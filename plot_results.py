import matplotlib.pyplot as plt

#Para 100 salidas, alpha = 0.1, epochs = 15, loss_alpha = 0.01, 35000 casos
#Precision History
[0.06837195305446886, 0.13255079626578803, 0.19658227848101265, 0.1772428884026258, 0.33847850055126794, 0.2069010586851392, 0.29778393351800553,
    0.4427906976744186, 0.3674818241903503, 0.5448334756618275, 0.40493319630010277, 0.524263431542461, 0.5761802575107297, 0.49001663893510816, 0.5885286783042394]
#Recall History
[0.5111361079865017, 0.4344206974128234, 0.3493813273340832, 0.40089988751406075, 0.27626546681664793, 0.3561304836895388, 0.24184476940382452, 0.2141732283464567,
    0.25016872890888636, 0.1435320584926884, 0.17727784026996626, 0.1361079865016873, 0.12080989876265467, 0.13250843644544433, 0.1061867266591676]
#Accuracy History
[0.9246889221271043, 0.965559803783398, 0.978998549742909, 0.9751433208614254, 0.9872318274603226, 0.9797009469860566, 0.9865771659521461, 0.9893367460595287,
    0.9880728856479103, 0.9901346147726188, 0.989054877910175, 0.9900232313910193, 0.9902187205913776, 0.9898413809720814, 0.9902187205913776]
#F1 score History
[0.12061048440610485, 0.20312417819386736, 0.25159983799108954, 0.24581005586592172, 0.3042239563978695, 0.261739417989418, 0.26691495965238976,
    0.2887035633055345, 0.2976843796011243, 0.2272079772079772, 0.2465967767172587, 0.21611001964636542, 0.1997396317649247, 0.2086063396493714, 0.17991233085572708]

#Para 100 salidas, alpha = 0.1, epochs = 15, loss_alpha = 0.01, 35000 casos
#Precision History
[0.42857142857142855, 0.3513909224011713, 0.48567335243553006, 0.639269406392694, 0.7572254335260116, 0.8, 0.8571428571428571,
    0.8490566037735849, 0.9, 0.8088235294117647, 0.7368421052631579, 0.8214285714285714, 0.8666666666666667, 0.9166666666666666, 1.0]
#Recall History
[0.08841394825646794, 0.10798650168728909, 0.07626546681664792, 0.031496062992125984, 0.029471316085489314, 0.014398200224971878, 0.01079865016872891, 0.010123734533183352,
    0.006074240719910012, 0.012373453318335208, 0.0031496062992125984, 0.005174353205849269, 0.005849268841394826, 0.0024746906636670418, 0.0017997750281214847]
#Accuracy History
[0.9895981560367519, 0.988973045221653, 0.9898504734930283, 0.990034597042203, 0.9900982446888312, 0.9900050463491256, 0.9899868613072318, 0.9899800419165216,
    0.9899504912234441, 0.9899914075677052, 0.9899163942698933, 0.9899368524420238, 0.9899459449629707, 0.98991866740013, 0.9899141211396566]
#F1 score History
[0.1465870943677732, 0.16520392359318534, 0.1318296713980167, 0.060034305317324184, 0.056734517106972714, 0.028287292817679555, 0.021328593645856476, 0.020008892841262782,
    0.01206703910614525, 0.02437403057832927, 0.006272401433691756, 0.010283925776883524, 0.011620111731843576, 0.004936055642809065, 0.0035930833146193574]

#Para 100 salidas, alpha = 0.1, epochs = 20, loss_alpha = 0.01, 35000 casos
#Precision History
[0.07744731729188462, 0.07842587399513928, 0.17098160185083178, 0.16335503508920268, 0.2358959368605671, 0.31048069345941687, 0.2873144047929148, 0.3980263157894737, 0.3338914936369725, 0.42957437472575694,
    0.5664739884393064, 0.34713820381572824, 0.38326446280991733, 0.495260663507109, 0.5956204379562043, 0.563845050215208, 0.6963788300835655, 0.6720647773279352, 0.6151898734177215, 0.5910224438902744]
#Recall History
[0.5829021372328459, 0.5662542182227221, 0.34915635545556806, 0.4346456692913386, 0.36310461192350957, 0.2659167604049494, 0.2481439820022497, 0.21777277840269965, 0.22429696287964004, 0.2202474690663667,
    0.13228346456692913, 0.16782902137232847, 0.16692913385826771, 0.09403824521934759, 0.09178852643419573, 0.08841394825646794, 0.0562429696287964, 0.07469066366704162, 0.0546681664791901, 0.05331833520809899]
#Accuracy History
[0.9256277249148712, 0.9283850318920173, 0.9763185291938117, 0.9717950000227313, 0.981680843422243, 0.9866158091661704, 0.9861839144211928, 0.9887684635003477, 0.9876409909029328, 0.9891662612917744,
    0.9902096280704307, 0.9884024895322353, 0.9888684812307637, 0.989877751055869, 0.9901937161587736, 0.9900982446888312, 0.9902164474611408, 0.9902823682380059, 0.9901027909493046, 0.9900618746050436]
#F1 score History
[0.13672823218997363, 0.13777060127534962, 0.22955184144357346, 0.23746312684365778, 0.2859927350048729, 0.2864760058167717, 0.2662964751327861, 0.28151810382434195, 0.26833535190418517, 0.29119571683521717,
    0.21448112347255155, 0.22626630269942372, 0.23256542861620436, 0.15806390622045755, 0.1590643274853801, 0.1528588098016336, 0.10407993338884262, 0.13444017007491396, 0.10041322314049586, 0.09781262897234834]

#Para 50 salidas, alpha = 0.1, epochs = 20, loss_alpha = 0.01, 35000 casos
#Precision History
precision_1 = [0.09607583409222618, 0.09452859862594157, 0.154477050413845, 0.1872952737482452, 0.2945480292659901, 0.34654017857142855, 0.40551011622901423, 0.49060272197018795, 0.5760869565217391, 0.47789634146341464,
    0.476221928665786, 0.5204795204795205, 0.540162980209546, 0.591869918699187, 0.4722524483133841, 0.4643188137164041, 0.5454545454545454, 0.5741935483870968, 0.6649874055415617, 0.5953878406708596]
#Recall History
recall_1 = [0.5221597300337458, 0.5138357705286839, 0.46186726659167604, 0.36017997750281217, 0.2807649043869516, 0.2794150731158605, 0.21192350956130485, 0.1703037120359955, 0.11923509561304838, 0.14105736782902137,
    0.16220472440944883, 0.1172103487064117, 0.10438695163104612, 0.08188976377952756, 0.09763779527559055, 0.11271091113610798, 0.09313835770528683, 0.10011248593925759, 0.059392575928009, 0.06389201349831271]
#Accuracy History
accuracy_1 = [0.9455335263978615, 0.945356222239397, 0.9690195080036915, 0.9777437818522374, 0.9859384163556267, 0.9873954928373666, 0.9888980319238411, 0.9898300153208978, 0.9902141743309041, 0.9897640945440328,
    0.9897322707207187, 0.9899891344374685, 0.9900527820840967, 0.9901527998145125, 0.9897800064556899, 0.989720905069535, 0.9900527820840967, 0.9901573460749861, 0.9901937161587736, 0.9901027909493046]
#F1 score History
f1_score_1 = [0.1622906688109639, 0.15968119690984728, 0.23151959402311809, 0.24644039097975837, 0.28749136143745685, 0.30937850292689, 0.2783687943262412, 0.2528390113560455, 0.19757688723205966, 0.21782178217821785,
    0.24198691055546234, 0.19133308850532502, 0.17496229260935142, 0.14387351778656124, 0.16181953765846382, 0.18139029688631428, 0.15910837817063794, 0.17049808429118773, 0.10904584882280051, 0.11540024380333197]

#Para 50 salidas, alpha = 0.1, epochs = 20, loss_alpha = 0.01, 35000 casos
#Precision History
[0.08615630834889304, 0.12874834978311436, 0.24647028063447796, 0.18812217194570136, 0.31962338949454905, 0.20470031984424975, 0.4668639053254438, 0.41921808761187, 0.32154445165476964, 0.3633633633633634, 0.4388451443569554, 0.48442534908700324,
    0.5104510451045104, 0.572901325478645, 0.4688869412795793, 0.5321100917431193, 0.5968992248062015, 0.5572519083969466, 0.5266272189349113, 0.650137741046832, 0.5761194029850746, 0.5909090909090909, 0.5355329949238579, 0.5958702064896755, 0.5723684210526315]
#Recall History
[0.4359955005624297, 0.4607424071991001, 0.31811023622047246, 0.3741282339707537, 0.29021372328458944, 0.3311586051743532, 0.17750281214848143, 0.20022497187851518, 0.22294713160854893, 0.19055118110236222, 0.18807649043869518, 0.10146231721034871, 0.10438695163104612,
    0.0875140607424072, 0.1203599550056243, 0.0782902137232846, 0.10393700787401575, 0.06569178852643419, 0.08008998875140608, 0.0530933633295838, 0.04341957255343082, 0.06141732283464567, 0.047469066366704164, 0.045444319460067495, 0.0391451068616423]
#Accuracy History
[0.9475747973504394, 0.9630479948718181, 0.9832834002391333, 0.9773618959724678, 0.986586258473093, 0.9802419519823968, 0.9896413455112497, 0.9891162524265665, 0.9873954928373666, 0.9884479521369698, 0.9893662967526061, 0.9898300153208978, 0.9899391255722605,
    0.9901209759911984, 0.9897345438509554, 0.9899914075677052, 0.9902369056332714, 0.9900323239119662, 0.9899777687862849, 0.9901437072935657, 0.9900118657398357, 0.9900868790376476, 0.9899595837443911, 0.9900436895631498, 0.9899959538281786]
#F1 score History
[0.14388061917665837, 0.20125786163522014, 0.2777450402671381, 0.2503575461046293, 0.30420940926777507, 0.253007906497078, 0.2572127139364303, 0.2710109622411693, 0.26331871927726846, 0.25, 0.26330708661417324, 0.16778273809523808, 0.173328352633545,
    0.1518345042935207, 0.19155030433225922, 0.13649735242204356, 0.17704541099827553, 0.11752867780237472, 0.13903534465924625, 0.09816971713810317, 0.0807531380753138, 0.11126961483594865, 0.0872081008472825, 0.08444816053511706, 0.07327858496525586]

###### 28 NOV ###################################################################################

# 48 bits, 35k triplets, 25 epochs, val_loss 0.05, training_loss 0.01

plt.ylabel('precision')
plt.xlabel('recall')
plt.plot(recall_1, precision_1, 'ro')
plt.show()

#plt.ylabel('accuracy')
#plt.xlabel('epoch')
#plt.plot(range(len(accuracy_2)), accuracy_2, 'ro', range(len(accuracy_2)), accuracy_4, 'b>')
#plt.show()
