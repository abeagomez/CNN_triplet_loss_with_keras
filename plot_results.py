import matplotlib.pyplot as plt
import pylab
import numpy as np

def sort_pairs(r, p):
    r.append(1.0)
    p.append(0.2)
    sorting = np.argsort(np.array(r))
    p.append(0.1)
    r = [r[i] for i in sorting]
    p = [p[i] for i in sorting]
    f = np.polyfit(r, p, 3)
    return r, np.polyval(f, r)


###### 28 NOV ###################################################################################

# 48 bits, 35k triplets, 25 epochs, val_loss 0.05, training_loss 0.01
#True positives
tp_2 = [1038, 1070, 722, 320, 328, 202, 316, 136, 44, 64, 74,
    38, 26, 32, 24, 2, 4, 14, 6, 10, 6, 2, 8, 2, 4]
#True negatives
tn_2 = [869520, 869792, 870558, 870826, 870844, 870878, 870842, 870898, 870954, 870952, 870934, 870952, 870952,
    870948, 870950, 870952, 870954, 870954, 870954, 870954, 870954, 870952, 870954, 870954, 870954]
#False, positives
fp_2 = [1434, 1162, 396, 128, 110, 76, 112, 56, 0, 2,
    20, 2, 2, 6, 4, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0]
#False Negatives
fn_2 = [7852, 7820, 8168, 8570, 8562, 8688, 8574, 8754, 8846, 8826, 8816, 8852, 8864,
    8858, 8866, 8888, 8886, 8876, 8884, 8880, 8884, 8888, 8882, 8888, 8886]
#Precision History
p_2 = [0.4199029126213592, 0.47939068100358423, 0.6457960644007156, 0.7142857142857143, 0.7488584474885844, 0.7266187050359713, 0.7383177570093458, 0.7083333333333334,
    1.0, 0.9696969696969697, 0.7872340425531915, 0.95, 0.9285714285714286, 0.8421052631578947, 0.8571428571428571, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0]
#Recall History
r_2 = [0.11676040494938132, 0.1203599550056243, 0.081214848143982, 0.0359955005624297, 0.03689538807649044, 0.022722159730033747, 0.03554555680539932, 0.015298087739032622, 0.0049493813273340835, 0.007199100112485939, 0.008323959505061868, 0.0042744656917885265, 0.002924634420697413,
    0.0035995500562429695, 0.0026996625421822273, 0.0002249718785151856, 0.0004499437570303712, 0.0015748031496062992, 0.0006749156355455568, 0.0011248593925759281, 0.0006749156355455568, 0.0002249718785151856, 0.0008998875140607424, 0.0002249718785151856, 0.0004499437570303712]
#Accuracy History
a_2 = [0.9894458563108914, 0.9897913721068735, 0.9902664563263488, 0.9901141566004883, 0.9901437072935657, 0.9900391433026764, 0.9901277953819086, 0.9899868613072318, 0.9899459449629707, 0.9899664031351012, 0.9899573106141544, 0.9899368524420238,
    0.9899232136606034, 0.9899254867908402, 0.98991866740013, 0.9898959360977628, 0.9899004823582362, 0.9899118480094199, 0.989902755488473, 0.9899073017489464, 0.989902755488473, 0.9898959360977628, 0.9899050286187097, 0.9898982092279995, 0.9899004823582362]
#F1 score History
f1_2 = [0.18271431086076395, 0.1924114367919439, 0.1442845723421263, 0.06853715999143287, 0.07032590051457976, 0.04406631762652705, 0.0678257136724619, 0.029949350363356088, 0.009850011193194539, 0.014292094685127288, 0.016473731077471063, 0.00851063829787234, 0.0058309037900874635,
    0.007168458781362007, 0.005382372729311504, 0.0004497413986957499, 0.0008994827973914998, 0.003144654088050314, 0.0013489208633093528, 0.0022471910112359553, 0.0013489208633093528, 0.0004497413986957499, 0.0017981568891885817, 0.00044984255510571296, 0.0008994827973914998]

# 48 bits, 35k triplets, 25 epochs, val_loss 0.1, training_loss 0.01
#True positives
tp_3 = [5564, 3786, 3922, 3514, 3396, 3022, 2646, 2168, 1810, 2072, 1640, 1428,
    1238, 1044, 1366, 716, 652, 570, 426, 496, 512, 302, 306, 272, 288]
#True negatives
tn_3 = [791110, 849138, 849644, 856836, 857228, 863402, 862928, 868194, 869384, 868566, 868970, 869308, 869982,
    870252, 869674, 870300, 870504, 870596, 870760, 870580, 870646, 870802, 870766, 870798, 870846]
#False, positives
fp_3 = [79844, 21816, 21310, 14118, 13726, 7552, 8026, 2760, 1570, 2388, 1984,
    1646, 972, 702, 1280, 654, 450, 358, 194, 374, 308, 152, 188, 156, 108]
#False Negatives
fn_3 = [3326, 5104, 4968, 5376, 5494, 5868, 6244, 6722, 7080, 6818, 7250, 7462, 7652,
    7846, 7524, 8174, 8238, 8320, 8464, 8394, 8378, 8588, 8584, 8618, 8602]
#Precision History
p_3 = [0.06514612214312476, 0.1478790719475041, 0.15543753963221307, 0.1992967332123412, 0.19834131526690807, 0.28579534707773785, 0.24793853073463268, 0.43993506493506496, 0.5355029585798816, 0.46457399103139013, 0.45253863134657835, 0.4645413142485361,
    0.5601809954751131, 0.5979381443298969, 0.5162509448223734, 0.5226277372262774, 0.5916515426497277, 0.6142241379310345, 0.6870967741935484, 0.5701149425287356, 0.624390243902439, 0.6651982378854625, 0.6194331983805668, 0.6355140186915887, 0.7272727272727273]
#Recall History
r_3 = [0.6258717660292463, 0.42587176602924637, 0.44116985376827894, 0.3952755905511811, 0.38200224971878516, 0.33993250843644546, 0.29763779527559053, 0.2438695163104612, 0.20359955005624297, 0.23307086614173228, 0.1844769403824522, 0.16062992125984252, 0.1392575928008999,
    0.11743532058492688, 0.15365579302587176, 0.08053993250843644, 0.0733408323959505, 0.06411698537682789, 0.047919010123734535, 0.05579302587176603, 0.05759280089988751, 0.03397075365579302, 0.034420697412823394, 0.030596175478065243, 0.032395950506186724]
#Accuracy History
a_3 = [0.9054718791058415, 0.9694036670136978, 0.9701333418196862, 0.9778437995826533, 0.9781552184250845, 0.9847472961115834, 0.9837812157609758, 0.9892230895476926, 0.9901687117261696, 0.9895367815203604, 0.9895049576970463, 0.98964816490196, 0.990198262419247,
    0.9902846413682426, 0.9899936806979419, 0.9899664031351012, 0.9901255222516719, 0.9901368879028555, 0.9901596192052228, 0.990034597042203, 0.9901277953819086, 0.9900664208655171, 0.9900300507817295, 0.9900277776514927, 0.9901005178190679]
#F1 score History
f1_3 = [0.11800886551146365, 0.21952916618346288, 0.22988101518082174, 0.2649875574994344, 0.26111025680455174, 0.3105219893136046, 0.2705244862488498, 0.31379360254740196, 0.29502852485737574, 0.3104119850187266, 0.26210644078631934, 0.238716148445336, 0.22306306306306306,
    0.19631440391124483, 0.23682385575589462, 0.13957115009746585, 0.13050440352281825, 0.11611326135669177, 0.08958990536277602, 0.1016393442622951, 0.1054582904222451, 0.0646404109589041, 0.06521739130434782, 0.0583816269585748, 0.06202886065044152]

# 48 bits, 35k triplets, 25 epochs, val_loss 0.1, training_loss 0.05
#True positives
tp_5 = [910, 684, 338, 260, 338, 246, 198, 112, 92, 64, 56,
    54, 54, 46, 42, 16, 24, 22, 18, 6, 12, 8, 4, 8, 4]
#True negatives
tn_5 = [869262, 870166, 870806, 870842, 870816, 870888, 870888, 870928, 870924, 870936, 870940, 870942, 870934,
    870940, 870950, 870954, 870954, 870948, 870954, 870954, 870950, 870954, 870954, 870954, 870954]
#False, positives
fp_5 = [1692, 788, 148, 112, 138, 66, 66, 26, 30, 18, 14,
    12, 20, 14, 4, 0, 0, 6, 0, 0, 4, 0, 0, 0, 0]
#False Negatives
fn_5 = [7980, 8206, 8552, 8630, 8552, 8644, 8692, 8778, 8798, 8826, 8834, 8836, 8836,
    8844, 8848, 8874, 8866, 8868, 8872, 8884, 8878, 8882, 8886, 8882, 8886]
#Precision History
p_5 = [0.34973097617217525, 0.46467391304347827, 0.6954732510288066, 0.6989247311827957, 0.7100840336134454, 0.7884615384615384, 0.75, 0.8115942028985508, 0.7540983606557377,
    0.7804878048780488, 0.8, 0.8181818181818182, 0.7297297297297297, 0.7666666666666667, 0.9130434782608695, 1.0, 1.0, 0.7857142857142857, 1.0, 1.0, 0.75, 1.0, 1.0, 1.0, 1.0]
#Recall History
r_5 = [0.10236220472440945, 0.07694038245219348, 0.03802024746906637, 0.02924634420697413, 0.03802024746906637, 0.02767154105736783, 0.022272215973003374, 0.012598425196850394, 0.010348706411698537, 0.007199100112485939, 0.006299212598425197, 0.006074240719910012, 0.006074240719910012,
    0.005174353205849269, 0.004724409448818898, 0.0017997750281214847, 0.0026996625421822273, 0.0024746906636670418, 0.0020247469066366703, 0.0006749156355455568, 0.0013498312710911137, 0.0008998875140607424, 0.0004499437570303712, 0.0008998875140607424, 0.0004499437570303712]
#Accuracy History
a_5 = [0.9890071421752038, 0.9897777333254532, 0.9901118834702516, 0.9900641477352804, 0.9901232491214351, 0.9901005178190679, 0.9900459626933865, 0.9899936806979419, 0.9899664031351012, 0.9899482180932074, 0.989943671832734, 0.989943671832734, 0.9899345793117871,
    0.9899323061815504, 0.9899391255722605, 0.9899141211396566, 0.9899232136606034, 0.9899141211396566, 0.9899163942698933, 0.989902755488473, 0.9899050286187097, 0.9899050286187097, 0.9899004823582362, 0.9899050286187097, 0.9899004823582362]
#F1 score History
f1_5 = [0.15837104072398192, 0.13202084539664158, 0.07209897610921502, 0.056143381559058514, 0.07217595558402734, 0.053466637687459254, 0.043259777146602583, 0.02481169694284448, 0.020417221482467822, 0.014266607222469904, 0.012500000000000002, 0.01205895489057615, 0.012048192771084336,
    0.010279329608938547, 0.009400179051029543, 0.0035930833146193574, 0.005384787973973525, 0.004933841668535547, 0.004041311180960934, 0.0013489208633093528, 0.002694812485964518, 0.0017981568891885817, 0.0008994827973914998, 0.0017981568891885817, 0.0008994827973914998]

# 48 bits, 35k triplets, 25 epochs, val_loss 0.2, training_loss 0.01
#True positives
tp_6 = [7642, 7696, 6900, 7326, 7466, 7226, 7370, 6932, 6892, 6054, 6218, 5974, 6492,
    5106, 5192, 5876, 5804, 5510, 4912, 4816, 5496, 4948, 4390, 4582, 4664]
#True negatives
tn_6 = [420556, 478458, 710736, 620306, 558086, 663250, 659868, 719974, 737594, 800924, 795248, 804904, 768640,
    831352, 835958, 813322, 809824, 831092, 836522, 840534, 819198, 827598, 848156, 841700, 840478]
#False, positives
fp_6 = [450398, 392496, 160218, 250648, 312868, 207704, 211086, 150980, 133360, 70030, 75706, 66050,
    102314, 39602, 34996, 57632, 61130, 39862, 34432, 30420, 51756, 43356, 22798, 29254, 30476]
#False Negatives
fn_6 = [1248, 1194, 1990, 1564, 1424, 1664, 1520, 1958, 1998, 2836, 2672, 2916, 2398,
    3784, 3698, 3014, 3086, 3380, 3978, 4074, 3394, 3942, 4500, 4308, 4226]
#Precision History
p_6 = [0.016684132390184264, 0.019230769230769232, 0.04128819157720892, 0.028398210672393343, 0.023306923398702606, 0.03362024845298469, 0.033736770791372175, 0.04389786716652313, 0.049140119213986255, 0.07956994900373272, 0.07589961427664665, 0.0829445740308786,
    0.05966582725217359, 0.11420774805403955, 0.12919279386881657, 0.09252377653209044, 0.08671228374219381, 0.12144053601340034, 0.12484749898332656, 0.13667839709388127, 0.09599664640536575, 0.10243458098708182, 0.16146829483595704, 0.13541789809670174, 0.13272623790552077]
#Recall History
r_6 = [0.8596175478065242, 0.8656917885264342, 0.7761529808773904, 0.8240719910011248, 0.8398200224971879, 0.8128233970753656, 0.829021372328459, 0.7797525309336333, 0.7752530933633296, 0.6809898762654668, 0.699437570303712, 0.6719910011248594, 0.7302587176602925,
    0.5743532058492689, 0.5840269966254218, 0.6609673790776153, 0.6528683914510686, 0.6197975253093363, 0.5525309336332959, 0.5417322834645669, 0.6182227221597301, 0.5565804274465692, 0.4938132733408324, 0.5154105736782902, 0.5246344206974128]
#Accuracy History
a_6 =[0.4866749105523252, 0.552545678552107, 0.8156400452807543, 0.7133446383677107, 0.6427866758198044, 0.7620396342988075, 0.7583594364455517, 0.8261760039279691, 0.8461568187087711, 0.9171830460854424, 0.9109182991530317, 0.9216156500470538,
    0.8809879933260897, 0.950688985774751, 0.956021749310105, 0.9310718718318247, 0.9270143343592728, 0.9508526511517951, 0.9563445338037198, 0.9607953228072249, 0.9373184337223417, 0.9462427430317193, 0.968974045398957, 0.9618546014975382, 0.9605589172626057]
#F1 score History
f1_6 = [0.032732957830938256, 0.03762570829320283, 0.07840552702149903, 0.05490437076563343, 0.04535513814302724, 0.06456974354391921, 0.0648350971646741, 0.08311650939437178, 0.09242198709954272, 0.14249064419704854, 0.1369392384434118, 0.1476629507872556,
    0.11031810766721044, 0.1905294973693048, 0.2115815640409145, 0.162324926102931, 0.15309136948723362, 0.20308871770299658, 0.20367375710080024, 0.2182840048950732, 0.1661878987632669, 0.17302514249746478, 0.24336160541049948, 0.21448298459954127, 0.2118555530320236]

# 48 bits, 35k triplets, 25 epochs, val_loss 0.2, training_loss 0.05
#True positives
tp_7 = [4678, 3918, 3088, 2888, 2340, 2990, 2486, 1948, 2110, 1526, 1470, 1278,
    1380, 1032, 868, 688, 896, 650, 962, 596, 606, 636, 516, 396, 320]
#True negatives
tn_7 = [811480, 844486, 859214, 862872, 865428, 861600, 866390, 868014, 867400, 868716, 869260, 868932, 868852,
    869570, 870068, 870482, 869826, 870340, 869966, 870476, 870684, 870630, 870666, 870746, 870820]
#False, positives
fp_7 = [59474, 26468, 11740, 8082, 5526, 9354, 4564, 2940, 3554, 2238, 1694, 2022,
    2102, 1384, 886, 472, 1128, 614, 988, 478, 270, 324, 288, 208, 134]
#False Negatives
fn_7 = [4212, 4972, 5802, 6002, 6550, 5900, 6404, 6942, 6780, 7364, 7420, 7612, 7510,
    7858, 8022, 8202, 7994, 8240, 7928, 8294, 8284, 8254, 8374, 8494, 8570]
#Precision History
p_7 = [0.07292056366130441, 0.12894095965247154, 0.20825465335851093, 0.26326344576116684, 0.2974828375286041, 0.24222294232015554, 0.3526241134751773, 0.3985270049099836, 0.3725282485875706, 0.40541976620616366, 0.4646017699115044, 0.38727272727272727,
    0.39632395175186674, 0.4271523178807947, 0.49486887115165334, 0.593103448275862, 0.4426877470355731, 0.5142405063291139, 0.49333333333333335, 0.5549348230912476, 0.6917808219178082, 0.6625, 0.6417910447761194, 0.6556291390728477, 0.7048458149779736]
#Recall History
r_7 = [0.5262092238470191, 0.4407199100112486, 0.34735658042744655, 0.324859392575928, 0.26321709786276715, 0.3363329583802025, 0.2796400449943757, 0.21912260967379077, 0.2373453318335208, 0.17165354330708663, 0.16535433070866143, 0.1437570303712036, 0.15523059617547807,
    0.11608548931383578, 0.09763779527559055, 0.07739032620922384, 0.10078740157480315, 0.07311586051743532, 0.10821147356580428, 0.0670416197975253, 0.06816647919010124, 0.07154105736782902, 0.05804274465691789, 0.04454443194600675, 0.0359955005624297]
#Accuracy History
a_7 = [0.9276167138720046, 0.9642663926787022, 0.9800623746936957, 0.9839926168729911, 0.9862748396306618, 0.9826628356845077, 0.9875341537818068, 0.9887684635003477, 0.9882547360668482, 0.9890867017334891, 0.9896413455112497, 0.9890503316497016,
    0.9890753360823055, 0.9894958651760994, 0.9898754779256322, 0.990141434163329, 0.9896322529903028, 0.9899368524420238, 0.9898663854046854, 0.9900300507817295, 0.9902778219775323, 0.9902505444146917, 0.9901550729447492, 0.9901096103400148, 0.9901073372097781]
#F1 score History
f1_7 = [0.128090687549629, 0.19951115184845705, 0.26039295050172867, 0.29083585095669684, 0.27930293626163755, 0.28162381086936045, 0.3119196988707654, 0.2827696327478588, 0.2899546516421602, 0.24118855697803065, 0.24390243902439027, 0.20968006562756358, 0.2230843840931135,
    0.18255793384043875, 0.1630965802329951, 0.13691542288557215, 0.1641927799157046, 0.1280283632066181, 0.1774907749077491, 0.11963067041348854, 0.12410403440507886, 0.12913705583756346, 0.10645760264080875, 0.08342110806825362, 0.06849315068493152]

# 48 bits, 35k triplets, 50 epochs, val_loss 0.2, training_loss 0.01
#True positives
tp_8 = [7288, 7430, 7070, 7154, 7202, 6862, 6732, 7164, 6992, 6708, 6662, 5926, 5568, 5928, 5444, 5394, 4696, 4962, 5074, 4908, 4366, 4438, 3812, 3412, 3454,
    3470, 4718, 3344, 3120, 3224, 2698, 3128, 2672, 2926, 2856, 2822, 2758, 3332, 2338, 2866, 2564, 2330, 2398, 3194, 3254, 2488, 2530, 2140, 2360, 2508]
#True negatives
tn_8 = [559394, 571198, 681868, 690532, 656242, 722798, 746646, 692734, 735404, 750830, 768828, 799852, 808116, 811250, 817256, 829044, 844036, 840164, 833962, 838700, 844930, 847456, 854044, 860286, 859352,
    856530, 844282, 858640, 861710, 859680, 864974, 860264, 863824, 864044, 863394, 863632, 864452, 858936, 866258, 862948, 864008, 867080, 866698, 861960, 857612, 866188, 865690, 866960, 866474, 865358]
#False, positives
fp_8 = [311560, 299756, 189086, 180422, 214712, 148156, 124308, 178220, 135550, 120124, 102126, 71102, 62838, 59704, 53698, 41910, 26918, 30790, 36992, 32254, 26024, 23498, 16910,
    10668, 11602, 14424, 26672, 12314, 9244, 11274, 5980, 10690, 7130, 6910, 7560, 7322, 6502, 12018, 4696, 8006, 6946, 3874, 4256, 8994, 13342, 4766, 5264, 3994, 4480, 5596]
#False Negatives
fn_8 = [1602, 1460, 1820, 1736, 1688, 2028, 2158, 1726, 1898, 2182, 2228, 2964, 3322, 2962, 3446, 3496, 4194, 3928, 3816, 3982, 4524, 4452, 5078, 5478, 5436,
    5420, 4172, 5546, 5770, 5666, 6192, 5762, 6218, 5964, 6034, 6068, 6132, 5558, 6552, 6024, 6326, 6560, 6492, 5696, 5636, 6402, 6360, 6750, 6530, 6382]
#Precision History
p_8 = [0.022857286230429548, 0.024187300202483185, 0.036042741491465975, 0.03813920757452979, 0.03245401371702551, 0.04426582719426131, 0.05137362637362637, 0.038644111681698526, 0.0490522091734366, 0.052888860855304656, 0.06123837187925139, 0.07693306330165654, 0.08139636873958425, 0.09032179424670893, 0.09204964323154442, 0.11402841197361745, 0.1485417852850003, 0.13878943835309912, 0.12061997812960586, 0.13207039448899413, 0.14366567949983547, 0.1588631156930126, 0.18395907730914005, 0.24232954545454546, 0.22941020191285866,
    0.19391974963674974, 0.15030264415418923, 0.21356495082386, 0.2523455192494338, 0.22237550006897502, 0.3109011292924637, 0.22637139962367925, 0.27259742909610285, 0.2974786498576657, 0.27419354838709675, 0.27819400630914826, 0.2978401727861771, 0.21706840390879478, 0.3323855558714814, 0.2636129506990434, 0.26961093585699264, 0.37556415215989686, 0.36038473098887885, 0.2620610436494913, 0.1960713424921668, 0.34298318169285913, 0.3246086733384655, 0.34887512226931855, 0.34502923976608185, 0.30947680157946694]
#Recall History
r_8 = [0.8197975253093364, 0.8357705286839145, 0.7952755905511811, 0.8047244094488188, 0.8101237345331833, 0.7718785151856018, 0.7572553430821147, 0.8058492688413949, 0.7865016872890889, 0.7545556805399325, 0.7493813273340832, 0.666591676040495, 0.6263217097862768, 0.6668166479190101, 0.6123734533183353, 0.6067491563554556, 0.5282339707536557, 0.5581552305961754, 0.5707536557930258, 0.5520809898762654, 0.4911136107986502, 0.49921259842519683, 0.42879640044994377, 0.3838020247469066, 0.3885264341957255,
    0.39032620922384703, 0.5307086614173229, 0.37615298087739035, 0.35095613048368957, 0.3626546681664792, 0.3034870641169854, 0.3518560179977503, 0.300562429696288, 0.3291338582677165, 0.32125984251968503, 0.3174353205849269, 0.3102362204724409, 0.37480314960629924, 0.262992125984252, 0.322384701912261, 0.28841394825646793, 0.26209223847019125, 0.2697412823397075, 0.3592800899887514, 0.36602924634420697, 0.2798650168728909, 0.2845894263217098, 0.2407199100112486, 0.265466816647919, 0.28211473565804274]
#Accuracy History
a_8 = [0.6440709944035533, 0.6576484013075045, 0.7830228995140047, 0.7929655711694346, 0.7540473083864867, 0.8293061042639377, 0.856263155741245, 0.7954796532112511, 0.8437813976113947, 0.8609912666336305, 0.8813948836384632, 0.9158191679434081, 0.9248048517691773, 0.9287760102927337, 0.9350521228763281, 0.9483931242356599, 0.9646391860375249, 0.9605407322207119, 0.953619050649888, 0.9588154263710384, 0.9652802087642809, 0.9682330049417851, 0.9750092061774587, 0.9816490195989289, 0.9806352035133501,
    0.9774460017912266, 0.9649437854892459, 0.9797009469860566, 0.9829356113129145, 0.9807465868949495, 0.986165729379299, 0.9813012306727101, 0.9848291288001054, 0.985367860666209, 0.9845495337809884, 0.9847813930651342, 0.9856406362946158, 0.9800237314796714, 0.9872159155486654, 0.9840539913893827, 0.984915507749101, 0.9881410795550121, 0.9877841981078463, 0.9833038584112638, 0.978430267183728, 0.9873068407581344, 0.9867885670641614, 0.9877887443683199, 0.9874864180468356, 0.9863862230122613]
#F1 score History
f1_8 = [0.04447454979282232, 0.0470140092889052, 0.06896013577441158, 0.07282685044740565, 0.062407930538465536, 0.08372989725943822, 0.09621953834059886, 0.07375150560548503, 0.09234507897934385, 0.0988491180501319, 0.1132242220296062, 0.1379454829023022, 0.14406955081763612, 0.15909395883094926, 0.1600423330197554, 0.19197779122326228, 0.23187833300414776, 0.2223018681958694, 0.19915220974958786, 0.2131503517762529, 0.22230142566191444, 0.24102536251561396, 0.2574631905984061, 0.29708315193730955, 0.28848241877557834,
    0.25910991636798086, 0.2342601787487587, 0.2724458204334365, 0.29359179448574385, 0.275696938600992, 0.30714936247723135, 0.27549762198344196, 0.28589771025037447, 0.31250667521093667, 0.29586656997824506, 0.29652201323946625, 0.30391184573002755, 0.2749174917491749, 0.29364481286109023, 0.29005161420908815, 0.27869565217391307, 0.3087319464687956, 0.30854348944930515, 0.30306480690767623, 0.25535588166051953, 0.3082259663032706, 0.30328458403260605, 0.2848775292864749, 0.3000635727908455, 0.29516299870542545]

# 48 bits, 35k triplets, 50 epochs, val_loss 0.2, training_loss 0.01
#True positives
tp_9 = [7812, 7794, 7612, 7662, 7388, 7618, 7272, 7210, 6806, 7264, 6702, 6656, 6706, 6002, 6360, 6318, 6050, 5640, 5480, 5400, 4460, 5108, 4718, 5134, 4724, 4882, 4208, 4776, 3280, 4274, 4490, 3744, 3598, 4222, 4026, 3914, 3598, 2740, 3224, 3514, 3268, 2758, 2772, 2940, 3298, 2776, 3620, 3220, 2452, 2622,
    2660, 3530, 2982, 3140, 2784, 3716, 2576, 2422, 2468, 3034, 2774, 2586, 2246, 2394, 2538, 2542, 2734, 2232, 2506, 3162, 2762, 1946, 2306, 3146, 2232, 2556, 2588, 2384, 2408, 1964, 2300, 2310, 2304, 2270, 2452, 2504, 2380, 1694, 1696, 2238, 1548, 2066, 2424, 2084, 1770, 1836, 2128, 1934, 2818, 2060]
#True negatives
tn_9 = [340112, 383556, 545606, 547326, 617394, 576242, 671782, 649770, 734820, 648526, 720936, 757094, 732572, 801182, 754660, 786584, 798504, 815052, 825514, 817428, 837008, 826706, 839654, 831942, 834850, 832914, 848564, 837166, 860246, 848436, 845388, 855696, 856536, 851104, 853816, 852524, 856706, 864460, 861168, 856062, 857704, 863630, 862886, 862504, 859832, 864162, 857444, 860540, 864280, 865302,
    864980, 857192, 862448, 860674, 864514, 856374, 865514, 864504, 866024, 861664, 863514, 865120, 867154, 865294, 864986, 865104, 863278, 866240, 866140, 861178, 863888, 867984, 865152, 861248, 865830, 864942, 864252, 866086, 866084, 867118, 866098, 866282, 866746, 866022, 865370, 864106, 863864, 868260, 868530, 866612, 869088, 866944, 865320, 866528, 867792, 867912, 866680, 867560, 859132, 866996]
#False, positives
fp_9 = [530842, 487398, 325348, 323628, 253560, 294712, 199172, 221184, 136134, 222428, 150018, 113860, 138382, 69772, 116294, 84370, 72450, 55902, 45440, 53526, 33946, 44248, 31300, 39012, 36104, 38040, 22390, 33788, 10708, 22518, 25566, 15258, 14418, 19850, 17138, 18430, 14248, 6494, 9786, 14892, 13250, 7324, 8068, 8450, 11122, 6792,
    13510, 10414, 6674, 5652, 5974, 13762, 8506, 10280, 6440, 14580, 5440, 6450, 4930, 9290, 7440, 5834, 3800, 5660, 5968, 5850, 7676, 4714, 4814, 9776, 7066, 2970, 5802, 9706, 5124, 6012, 6702, 4868, 4870, 3836, 4856, 4672, 4208, 4932, 5584, 6848, 7090, 2694, 2424, 4342, 1866, 4010, 5634, 4426, 3162, 3042, 4274, 3394, 11822, 3958]
#False Negatives
fn_9 = [1078, 1096, 1278, 1228, 1502, 1272, 1618, 1680, 2084, 1626, 2188, 2234, 2184, 2888, 2530, 2572, 2840, 3250, 3410, 3490, 4430, 3782, 4172, 3756, 4166, 4008, 4682, 4114, 5610, 4616, 4400, 5146, 5292, 4668, 4864, 4976, 5292, 6150, 5666, 5376, 5622, 6132, 6118, 5950, 5592, 6114, 5270, 5670, 6438, 6268,
    6230, 5360, 5908, 5750, 6106, 5174, 6314, 6468, 6422, 5856, 6116, 6304, 6644, 6496, 6352, 6348, 6156, 6658, 6384, 5728, 6128, 6944, 6584, 5744, 6658, 6334, 6302, 6506, 6482, 6926, 6590, 6580, 6586, 6620, 6438, 6386, 6510, 7196, 7194, 6652, 7342, 6824, 6466, 6806, 7120, 7054, 6762, 6956, 6072, 6830]
#Precision History
p_9 = [0.014502816279095672, 0.015739349585615278, 0.022861604997597307, 0.02312777325002264, 0.02831215414565354, 0.025197631726920914, 0.03522504892367906, 0.03156825485783339, 0.047614383657478665, 0.0316249586402661, 0.04276416539050536, 0.05522918118756016, 0.04622022496691663, 0.07920922743949112, 0.05185318049146379, 0.06966743119266056, 0.07707006369426751, 0.09164473042800039, 0.10761979575805185, 0.09164036248854496, 0.11612768838202364, 0.10349298970743172, 0.1309900605252929, 0.11629592715081774, 0.1157049083961987, 0.11374120497646895, 0.15820738401383563, 0.12384607405870761, 0.23448670288818987, 0.1595252314123619, 0.1493878094224115, 0.19703189137985475, 0.1997113676731794, 0.1753904951811233, 0.19022869022869024, 0.17517006802721088, 0.2016138070155777, 0.2967294780160277, 0.24780937740199846, 0.19091600565033143, 0.1978447753965371, 0.2735568339615156, 0.25571955719557193, 0.2581211589113257, 0.22871012482662967, 0.290133779264214, 0.21132516053706946, 0.23617427020683585, 0.26868288406749946, 0.31689630166787525,
    0.30808431781329626, 0.20414064307194077, 0.25957520891364905, 0.23397913561847988, 0.3018213356461405, 0.2031045037166594, 0.3213572854291417, 0.2729936880072137, 0.3336036766693701, 0.24618630314832846, 0.27158801644801256, 0.30712589073634206, 0.371485279523652, 0.297243605661783, 0.29837761580061134, 0.3029075309818875, 0.2626320845341018, 0.3213360207313562, 0.34234972677595626, 0.24439635183181327, 0.281033781033781, 0.39585028478437756, 0.2844104588061174, 0.24478680361033303, 0.3034257748776509, 0.29831932773109243, 0.27857911733046287, 0.3287369001654716, 0.33086012640835394, 0.3386206896551724, 0.32140860816098377, 0.33085075909481526, 0.3538083538083538, 0.31519022493751736, 0.3051269288203086, 0.2677502138579983, 0.25131995776135163, 0.386052871467639, 0.4116504854368932, 0.34012158054711245, 0.45342706502636204, 0.34002633311389074, 0.30081906180193596, 0.32012288786482335, 0.3588807785888078, 0.3763837638376384, 0.3323961262105592, 0.362987987987988, 0.1924863387978142, 0.34230641409106016]
#Recall History
r_9 = [0.878740157480315, 0.8767154105736783, 0.8562429696287964, 0.861867266591676, 0.8310461192350956, 0.856917885264342, 0.8179977502812148, 0.8110236220472441, 0.7655793025871767, 0.8170978627671541, 0.7538807649043869, 0.7487064116985377, 0.7543307086614173, 0.675140607424072, 0.7154105736782902, 0.7106861642294713, 0.6805399325084365, 0.6344206974128234, 0.6164229471316085, 0.6074240719910011, 0.5016872890888638, 0.5745781777277841, 0.5307086614173229, 0.5775028121484814, 0.5313835770528684, 0.5491563554555681, 0.4733408323959505, 0.5372328458942632, 0.3689538807649044, 0.48076490438695163, 0.5050618672665916, 0.42114735658042746, 0.4047244094488189, 0.4749156355455568, 0.4528683914510686, 0.4402699662542182, 0.4047244094488189, 0.30821147356580425, 0.3626546681664792, 0.3952755905511811, 0.36760404949381326, 0.3102362204724409, 0.31181102362204727, 0.33070866141732286, 0.37097862767154105, 0.3122609673790776, 0.40719910011248595, 0.36220472440944884, 0.27581552305961754, 0.2949381327334083, 0.2992125984251969,
    0.39707536557930256, 0.3354330708661417, 0.3532058492688414, 0.3131608548931384, 0.41799775028121483, 0.28976377952755905, 0.27244094488188975, 0.27761529808773905, 0.3412823397075366, 0.31203599550056244, 0.290888638920135, 0.25264341957255343, 0.2692913385826772, 0.28548931383577053, 0.2859392575928009, 0.3075365579302587, 0.25106861642294714, 0.28188976377952757, 0.3556805399325084, 0.3106861642294713, 0.2188976377952756, 0.259392575928009, 0.35388076490438697, 0.25106861642294714, 0.2875140607424072, 0.29111361079865017, 0.2681664791901012, 0.27086614173228346, 0.22092238470191225, 0.25871766029246346, 0.25984251968503935, 0.2591676040494938, 0.25534308211473566, 0.27581552305961754, 0.28166479190101235, 0.2677165354330709, 0.19055118110236222, 0.19077615298087738, 0.2517435320584927, 0.17412823397075367, 0.23239595050618672, 0.27266591676040497, 0.2344206974128234, 0.19910011248593926, 0.20652418447694038, 0.23937007874015748, 0.21754780652418448, 0.3169853768278965, 0.23172103487064116]
#Accuracy History
a_9 = [0.39543828224094274, 0.4447947590709262, 0.6287682816499288, 0.6307800019094294, 0.7101054277803792, 0.663594910006774, 0.7717890898841159, 0.7467005514613955, 0.8429062424702561, 0.7453480389705448, 0.82700796959461, 0.8680516091488946, 0.8402375875723423, 0.917417178499825, 0.8649487863757667, 0.9011847554793805, 0.9144280122385332, 0.9327699001186573, 0.9444787939680216, 0.9351976032114784, 0.956383177017744, 0.9454107773650784, 0.959683762121467, 0.9513913830178986, 0.9542305226835667, 0.9522097099031192, 0.9692309091157069, 0.9569219088838475, 0.9814535303985706, 0.9691604420783685, 0.9659416896631675, 0.9768095253249439, 0.9775983015170872, 0.9721336964280032, 0.9749932942658016, 0.9733975568396216, 0.9777915175872086, 0.9856292706434322, 0.982437795791072, 0.9769640981810411, 0.9785507430862744, 0.9847063797673223, 0.9838766872309183, 0.9836334622955888, 0.9810034506116994, 0.9853314905824214, 0.9786553070771636, 0.9817194866362673, 0.9850973581680389, 0.9864521437891263,
    0.9861293592955115, 0.9782666018066839, 0.9836175503839317, 0.9817808611526588, 0.9857406540250317, 0.9775482926518791, 0.9866408135987743, 0.9853178518010011, 0.9870977127763558, 0.9827855847172908, 0.9845927232554862, 0.9862043725933234, 0.9881297139038284, 0.9861839144211928, 0.9859975177417815, 0.9861361786862216, 0.9842790312828184, 0.9870749814739885, 0.9872727438045835, 0.9823786944049172, 0.9850041598283332, 0.9887320934165602, 0.9859225044439696, 0.9824400689213088, 0.9866089897754602, 0.985967967048704, 0.985220107200822, 0.9870727083437518, 0.9870977127763558, 0.9877682861961893, 0.9869908756552298, 0.987211369288192, 0.9877319161124017, 0.9868703997526834, 0.9863362141470533, 0.9849586972235987, 0.9845427143902783, 0.9887593709794009, 0.9890685166915953, 0.9875046030887293, 0.9895345083901237, 0.9876864535076673, 0.9862475620678212, 0.9872341005905593, 0.988313837453003, 0.9885252385650184, 0.9874568673537581, 0.9882365510249544, 0.9796623037720323, 0.9877387355031119]
#F1 score History
f1_9 = [0.028534693102289496, 0.030923540217663005, 0.04453415240602603, 0.04504673996119701, 0.05475878119464271, 0.04895572263993316, 0.06754158655855555, 0.06077105915274523, 0.08965290127115853, 0.0608931101256591, 0.08093714147696396, 0.10287003693800906, 0.08710335242697008, 0.14178399319663612, 0.09669768290457946, 0.1268954990058045, 0.13845977800663692, 0.16015447523852797, 0.18324694867079086, 0.15925445322637727, 0.18859945872801084, 0.17539401847337158, 0.21011846441613968, 0.19360434421902106, 0.19003177923488473, 0.18845055199567667, 0.2371505861136159, 0.20128966999620687, 0.2867383512544803, 0.23956056274872486, 0.23057566887485237, 0.26846407572063674, 0.2674496394856166, 0.25617377586311507, 0.26791774805350366, 0.2506243196516616, 0.2691502094554159, 0.3023615096005296, 0.2944292237442922, 0.2574736225087925, 0.2572418136020151, 0.2907442546911238, 0.2809934110491637, 0.2899408284023668, 0.282968682968683, 0.3007909849387799, 0.2782475019215988, 0.28591724382880485, 0.272202486678508, 0.30552318806804935,
    0.3035836566993837, 0.26965090520204715, 0.29266856413779563, 0.28148812191842226, 0.30738655183835706, 0.2733760023541529, 0.304743877913167, 0.2727170363697782, 0.30304518664047153, 0.28603752239087393, 0.29041038525963153, 0.29878682842287696, 0.30074986609534016, 0.28257790368271957, 0.2917912163715797, 0.294178914477491, 0.2833160621761658, 0.2818893660015156, 0.3091918568784701, 0.28971962616822433, 0.29511699967945293, 0.28190641749963785, 0.27132603835745384, 0.28939380001839754, 0.27477532931183063, 0.29281704662618857, 0.2847084708470847, 0.29537851567339857, 0.2978723404255319, 0.26739278420694346, 0.28667580705471774, 0.291078629032258, 0.2991819244253993, 0.28212776534924183, 0.28973177360274127, 0.27453130139239124, 0.25925925925925924, 0.2551589094743184, 0.2607225211375865, 0.2893341952165482, 0.2516254876462939, 0.27609247627956707, 0.2860514514987019, 0.27064935064935064, 0.2561134423383013, 0.2667054038349797, 0.27831545906356264, 0.2720495146996765, 0.23952401189970254, 0.27636168500134156]



# plt.figure(1)
# plt.subplot(321)
# plt.ylabel('validation cases')
# plt.xlabel('epoch')
# plt.title("Positives. val_loss:0.05 and training_loss:0.01")
# plt.plot([i for i in range(25)], tp_2,'r-o',
#          [i for i in range(25)], fp_2,  'b-o')
# plt.gca().legend(('true positives', 'false positives'))

# plt.subplot(322)
# plt.ylabel('validation cases')
# plt.xlabel('epoch')
# plt.title("Negatives. val_loss:0.05 and training_loss:0.01")
# plt.plot([i for i in range(25)], tn_2, 'r-o',
#          [i for i in range(25)], fn_2, 'b-o')
# plt.gca().legend(('true negatives', 'false negatives'))

# plt.subplot(323)
# plt.ylabel('validation cases')
# plt.xlabel('epoch')
# plt.title("Positives. val_loss:0.1 and training_loss:0.01")
# plt.plot([i for i in range(25)], tp_3, 'r-o',
#          [i for i in range(25)], fp_3,  'b-o')
# plt.gca().legend(('true positives', 'false positives'))

# plt.subplot(324)
# plt.ylabel('validation cases')
# plt.xlabel('epoch')
# plt.title("Negatives. val_loss:0.1 and training_loss:0.01")
# plt.plot([i for i in range(25)], tn_3, 'r-o',
#          [i for i in range(25)], fn_3, 'b-o')
# plt.gca().legend(('true negatives', 'false negatives'))

# plt.subplot(325)
# plt.ylabel('validation cases')
# plt.xlabel('epoch')
# plt.title("Positives. val_loss:0.1 and training_loss:0.05")
# plt.plot([i for i in range(25)], tp_5, 'r-o',
#          [i for i in range(25)], fp_5,  'b-o')
# plt.gca().legend(('true positives', 'false positives'))

# plt.subplot(326)
# plt.ylabel('validation cases')
# plt.xlabel('epoch')
# plt.title("Negatives. val_loss:0.1 and training_loss:0.05")
# plt.plot([i for i in range(25)], tn_5, 'r-o',
#          [i for i in range(25)], fn_5, 'b-o')
# plt.gca().legend(('true negatives', 'false negatives'))

# plt.figure(3)
# plt.subplot(321)
# plt.ylabel('validation cases')
# plt.xlabel('epoch')
# plt.title("Positives. val_loss:0.2 and training_loss:0.01")
# plt.plot([i for i in range(25)], tp_6, 'r-o',
#          [i for i in range(25)], fp_6,  'b-o')
# plt.gca().legend(('true positives', 'false positives'))

# plt.subplot(322)
# plt.ylabel('validation cases')
# plt.xlabel('epoch')
# plt.title("Negatives. val_loss:0.2 and training_loss:0.01")
# plt.plot([i for i in range(25)], tn_6, 'r-o',
#          [i for i in range(25)], fn_6, 'b-o')
# plt.gca().legend(('true negatives', 'false negatives'))

# plt.subplot(323)
# plt.ylabel('validation cases')
# plt.xlabel('epoch')
# plt.title("Positives. val_loss:0.2 and training_loss:0.05")
# plt.plot([i for i in range(25)], tp_7, 'r-o',
#          [i for i in range(25)], fp_7,  'b-o')
# plt.gca().legend(('true positives', 'false positives'))

# plt.subplot(324)
# plt.ylabel('validation cases')
# plt.xlabel('epoch')
# plt.title("Negatives. val_loss:0.2 and training_loss:0.05")
# plt.plot([i for i in range(25)], tn_7, 'r-o',
#          [i for i in range(25)], fn_7, 'b-o')
# plt.gca().legend(('true negatives', 'false negatives'))

# plt.subplot(325)
# plt.ylabel('validation cases')
# plt.xlabel('epoch')
# plt.title("Positives. val_loss:0.2 and training_loss:0.01, epoch 50")
# plt.plot([i for i in range(50)], tp_8, 'r-o',
#          [i for i in range(50)], fp_8,  'b-o')
# plt.gca().legend(('true positives', 'false positives'))

# plt.subplot(326)
# plt.ylabel('validation cases')
# plt.xlabel('epoch')
# plt.title("Negatives. val_loss:0.2 and training_loss:0.01, epoch 50")
# plt.plot([i for i in range(50)], tn_8, 'r-o',
#          [i for i in range(50)], fn_8, 'b-o')
# plt.gca().legend(('true negatives', 'false negatives'))
# #plt.show()


# plt.figure(2)
# plt.xlabel('Recall')
# plt.ylabel('Precision')
# plt.plot(r_2, p_2, 'ro',
#          r_3, p_3, 'bo',
#          r_5, p_5, "go",
#          #r_6, p_6, "yo",
#          r_7, p_7, 'mo',
#          r_8, p_8, 'co',
#          r_9, p_9, "ko")
# plt.gca().legend(('0.05 - 0.01', '0.1 - 0.01', "0.1 - 0.05", "0.2 - 0.01", "0.2 - 0.05", "0.2 - 0.01", "0.2 - 0.01"))
# #plt.show()

# x_2, y_2 = sort_pairs(r_2, p_2)
# x_3, y_3 = sort_pairs(r_3, p_3)
# x_5, y_5 = sort_pairs(r_5, p_5)
# x_6, y_6 = sort_pairs(r_6, p_6)
# x_7, y_7 = sort_pairs(r_7, p_7)
# x_8, y_8 = sort_pairs(r_8, p_8)
# x_9, y_9 = sort_pairs(r_8, p_8)

# plt.figure(4)
# plt.xlabel('Recall')
# plt.ylabel('Precision')
# plt.plot(x_2, y_2, 'r--',
#          x_3, y_3, 'b--',
#          x_5, y_5, "g--",
#          #x_6, y_6, "y-o",
#          x_7, y_7, "m--",
#          x_8, y_8, "c--",
#          x_9, y_9, "k--",)
#plt.show()

#plt.ylabel('accuracy')
#plt.xlabel('epoch')
#plt.plot(range(len(accuracy_2)), accuracy_2, 'ro', range(len(accuracy_2)), accuracy_4, 'b>')
#plt.show()

#### 3 December #########

#Loss from Prueba2 with 50 epochs
loss = [0.0035, 0.0022,  0.0018, 0.0016,
        0.0014, 0.0012, 0.0011, 0.0010, 9.4820e-04, 8.0417e-04, 8.1462e-04, 7.0352e-04,
        6.7314e-04, 5.3352e-04,  5.7486e-04, 4.9608e-04, 5.1346e-04, 4.4859e-04, 4.2586e-04,
        3.9402e-04, 4.0454e-04,  3.4687e-04, 3.0317e-04, 3.1102e-04,  3.1418e-04, 3.0825e-04,
        3.1747e-04, ]
plt.figure(5)
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.plot([i for i in range(len(loss))], loss, 'r-o')
#plt.show()

# Final result from scores on prueba 2
precision = [0.010032550276298857, 0.025872282143468584, 0.04306755553416284, 0.05495773732119636, 0.06864267840193286, 0.08384630519717795, 0.09694268403092138, 0.11321333158148295, 0.1313270246478873, 0.15154453525419034, 0.17421389156520978, 0.20331667423898228, 0.17421389156520978, 0.23397058823529412, 0.2737276478679505,
             0.3177221926556679, 0.38049713193116635, 0.4492099322799097, 0.4934402332361516, 0.5191304347826087, 0.5551982851018221, 0.6045454545454545, 0.6276223776223776, 0.6496945010183299, 0.665871121718377, 0.6956521739130435, 0.7299270072992701, 0.7373271889400922, 0.7947019867549668, 0.8709677419354839, 0.8913043478260869]
recall = [0.8944881889763779, 0.8499437570303712, 0.8051743532058493, 0.7606299212598425, 0.7158605174353205, 0.6710911136107987, 0.6263217097862768, 0.5815523059617548, 0.537007874015748, 0.4922384701912261, 0.44746906636670414, 0.4026996625421822, 0.44746906636670414, 0.35793025871766027, 0.31338582677165355, 0.2686164229471316,
          0.22384701912260968, 0.17907761529808774, 0.15230596175478064, 0.1343082114735658, 0.11653543307086614, 0.08976377952755905, 0.08076490438695164, 0.0717660292463442, 0.06276715410573679, 0.05399325084364454, 0.04499437570303712, 0.0359955005624297, 0.02699662542182227, 0.018222722159730035, 0.00922384701912261]
accuracy = [0.10710762362418792, 0.6751378653488573, 0.8172653334000118, 0.8654238705952418, 0.8989889116707053, 0.9225862766581349, 0.9372729711176072, 0.9497456367265106, 0.9594314446651907, 0.9670236996558481, 0.9729861202667746, 0.9780211037411177, 0.9729861202667746, 0.9816717509012961, 0.984660917162588,
            0.9867817476734512, 0.9884752296998104, 0.9894867726551525, 0.9898550197535018, 0.9899959538281786, 0.9901300685121454, 0.9902096280704307, 0.9902278131123244, 0.9902300862425611, 0.9902119012006674, 0.9902028086797205, 0.99018235050759, 0.9901300685121454, 0.9900982446888312, 0.9900527820840967, 0.9899777687862849]

x, y = sort_pairs(recall[-14:], precision[-14:])
plt.figure(6)
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.plot(x, y, 'r-o')


#CMC para los primeros 50 ranks con 48bits
CMC_results = [0.4557, 0.5968, 0.6492, 0.7025, 0.7406, 0.7724, 0.8009, 0.8217, 0.8402, 0.8577, 0.8627, 0.872, 0.8824, 0.8954, 0.903, 0.9102, 0.9174, 0.9216, 0.9282, 0.9339, 0.9345, 0.9356, 0.9381, 0.9447,
                0.9456, 0.9467, 0.9496, 0.9513, 0.9545, 0.9572, 0.9594, 0.9614, 0.9636, 0.9646, 0.9655, 0.9664, 0.9686, 0.97, 0.9716, 0.9732, 0.979, 0.9822, 0.9833, 0.9884, 0.9895, 0.9931, 0.9943, 0.9958, 0.9963, 0.9975]
cmc_paper = [0.7420, 0.9227, 0.9424, 0.9592]
plt.figure(7)
plt.xlabel('Rank')
plt.ylabel('Identification Rate')
plt.ylim(0, 1)
plt.plot([i for i in range(1, 51)], CMC_results, 'r-')
plt.plot([i for i in range(1,51,5)], CMC_results[0::5], 'ro')
plt.plot([i for i in range(1,21,5)],cmc_paper, "b->")
plt.show()
