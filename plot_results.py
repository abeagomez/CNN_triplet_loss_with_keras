import matplotlib.pyplot as plt

#Para 100 salidas, alpha = 0.1, epochs = 15, loss_alpha = 0.01, 35000 casos
#Precision History
[0.06837195305446886, 0.13255079626578803, 0.19658227848101265, 0.1772428884026258, 0.33847850055126794, 0.2069010586851392, 0.29778393351800553,
    0.4427906976744186, 0.3674818241903503, 0.5448334756618275, 0.40493319630010277, 0.524263431542461, 0.5761802575107297, 0.49001663893510816, 0.5885286783042394]
#Recall History
[0.5111361079865017, 0.4344206974128234, 0.3493813273340832, 0.40089988751406075, 0.27626546681664793, 0.3561304836895388, 0.24184476940382452, 0.2141732283464567,
    0.25016872890888636, 0.1435320584926884, 0.17727784026996626, 0.1361079865016873, 0.12080989876265467, 0.13250843644544433, 0.1061867266591676]
#Accuracy History
[0.9246889221271043, 0.965559803783398, 0.978998549742909, 0.9751433208614254, 0.9872318274603226, 0.9797009469860566, 0.9865771659521461, 0.9893367460595287,
    0.9880728856479103, 0.9901346147726188, 0.989054877910175, 0.9900232313910193, 0.9902187205913776, 0.9898413809720814, 0.9902187205913776]
#F1 score History
[0.12061048440610485, 0.20312417819386736, 0.25159983799108954, 0.24581005586592172, 0.3042239563978695, 0.261739417989418, 0.26691495965238976,
    0.2887035633055345, 0.2976843796011243, 0.2272079772079772, 0.2465967767172587, 0.21611001964636542, 0.1997396317649247, 0.2086063396493714, 0.17991233085572708]

#Para 100 salidas, alpha = 0.1, epochs = 15, loss_alpha = 0.01, 35000 casos
#Precision History
[0.42857142857142855, 0.3513909224011713, 0.48567335243553006, 0.639269406392694, 0.7572254335260116, 0.8, 0.8571428571428571,
    0.8490566037735849, 0.9, 0.8088235294117647, 0.7368421052631579, 0.8214285714285714, 0.8666666666666667, 0.9166666666666666, 1.0]
#Recall History
[0.08841394825646794, 0.10798650168728909, 0.07626546681664792, 0.031496062992125984, 0.029471316085489314, 0.014398200224971878, 0.01079865016872891, 0.010123734533183352,
    0.006074240719910012, 0.012373453318335208, 0.0031496062992125984, 0.005174353205849269, 0.005849268841394826, 0.0024746906636670418, 0.0017997750281214847]
#Accuracy History
[0.9895981560367519, 0.988973045221653, 0.9898504734930283, 0.990034597042203, 0.9900982446888312, 0.9900050463491256, 0.9899868613072318, 0.9899800419165216,
    0.9899504912234441, 0.9899914075677052, 0.9899163942698933, 0.9899368524420238, 0.9899459449629707, 0.98991866740013, 0.9899141211396566]
#F1 score History
[0.1465870943677732, 0.16520392359318534, 0.1318296713980167, 0.060034305317324184, 0.056734517106972714, 0.028287292817679555, 0.021328593645856476, 0.020008892841262782,
    0.01206703910614525, 0.02437403057832927, 0.006272401433691756, 0.010283925776883524, 0.011620111731843576, 0.004936055642809065, 0.0035930833146193574]

#Para 100 salidas, alpha = 0.1, epochs = 20, loss_alpha = 0.01, 35000 casos
#Precision History
[0.07744731729188462, 0.07842587399513928, 0.17098160185083178, 0.16335503508920268, 0.2358959368605671, 0.31048069345941687, 0.2873144047929148, 0.3980263157894737, 0.3338914936369725, 0.42957437472575694,
    0.5664739884393064, 0.34713820381572824, 0.38326446280991733, 0.495260663507109, 0.5956204379562043, 0.563845050215208, 0.6963788300835655, 0.6720647773279352, 0.6151898734177215, 0.5910224438902744]
#Recall History
[0.5829021372328459, 0.5662542182227221, 0.34915635545556806, 0.4346456692913386, 0.36310461192350957, 0.2659167604049494, 0.2481439820022497, 0.21777277840269965, 0.22429696287964004, 0.2202474690663667,
    0.13228346456692913, 0.16782902137232847, 0.16692913385826771, 0.09403824521934759, 0.09178852643419573, 0.08841394825646794, 0.0562429696287964, 0.07469066366704162, 0.0546681664791901, 0.05331833520809899]
#Accuracy History
[0.9256277249148712, 0.9283850318920173, 0.9763185291938117, 0.9717950000227313, 0.981680843422243, 0.9866158091661704, 0.9861839144211928, 0.9887684635003477, 0.9876409909029328, 0.9891662612917744,
    0.9902096280704307, 0.9884024895322353, 0.9888684812307637, 0.989877751055869, 0.9901937161587736, 0.9900982446888312, 0.9902164474611408, 0.9902823682380059, 0.9901027909493046, 0.9900618746050436]
#F1 score History
[0.13672823218997363, 0.13777060127534962, 0.22955184144357346, 0.23746312684365778, 0.2859927350048729, 0.2864760058167717, 0.2662964751327861, 0.28151810382434195, 0.26833535190418517, 0.29119571683521717,
    0.21448112347255155, 0.22626630269942372, 0.23256542861620436, 0.15806390622045755, 0.1590643274853801, 0.1528588098016336, 0.10407993338884262, 0.13444017007491396, 0.10041322314049586, 0.09781262897234834]

plt.ylabel('precision')
plt.xlabel('recall')
plt.plot(recall_2, precision_2, 'r-o', precision_4, recall_4, 'b->')
plt.show()

#plt.ylabel('accuracy')
#plt.xlabel('epoch')
#plt.plot(range(len(accuracy_2)), accuracy_2, 'ro', range(len(accuracy_2)), accuracy_4, 'b>')
#plt.show()
